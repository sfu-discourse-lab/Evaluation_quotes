{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n",
        "Script for cleaning up data in quotes excel sheet for VADER input\n",
        "\n",
        "Each row should contain:\n",
        "* Text id (from 'full' tab)\n",
        "* Text name ('full')\n",
        "* Quotes\n",
        " * All quotes in 'full' tab\n",
        " * All quotes from the same file in the same row\n",
        " * Quotes separated by newline (merge quotes)\n",
        "* Non-quotes ('non_quoted_text', copied as is)\n",
        "* Speaker ('full')\n",
        " * Merged and newline separated, as with Quotes\n",
        "* Verb ('full')\n",
        " * Merged and newline separated, as with Quotes\n",
        "\n",
        "Output CSV header names: text_id, text_name, quotes, non_quotes, speakers, verbs\n",
        "\n",
        "When quotes and non-quotes columns are merged, they are joined on common text id, so articles containing only non-quotes or only quotes (though I don't think there are any quotes-only articles) are omitted in the join. The final output contains 1-1 comparisons of the quotes and non-quotes in a given article.\n",
        "\n",
        "File naming convention:\n",
        "* input file to binder notebook does not have any special suffix\n",
        "* _qt: input from binder, contains extracted quotes and other details\n",
        "* _clean: output of this file; contains all the relevant into in one excel sheet/file; is the input for the sentiment_analysis notebook\n",
        "* _sentiment: output of the sentiment_analysis notebook containing the sentiments"
      ],
      "metadata": {
        "id": "IeD60Gz6NSyJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSKZ6yP8MnPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c54b4c3-cf5f-42d1-804d-9c8062912c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# run this code if connecting to a Google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "IkVT9cHLNSaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important!! Remember to replace file paths with the correct ones when running this code locally"
      ],
      "metadata": {
        "id": "-ICrpKpSehc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract relevant columns from both excel sheets\n",
        "\n",
        "# replace this with relevant file path\n",
        "fp = '/content/drive/My Drive/evaluation_quotes/CBC_input/2023_06_jun_CBC_news_qt.xlsx'\n",
        "\n",
        "full_df = pd.read_excel(fp, sheet_name = 'full', usecols = [\"text_id\", \"text_name\", \"quote\", \"speaker\", \"verb\"])\n",
        "\n",
        "non_quotes_df = pd.read_excel(fp, sheet_name = 'non_quoted_text')"
      ],
      "metadata": {
        "id": "qZXHHDGlPw3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check number of articles in the non_quoted_text sheet\n",
        "len(non_quotes_df)"
      ],
      "metadata": {
        "id": "2isgxFFJQYgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check number of articles in the full sheet\n",
        "unique_ids = full_df['text_id'].nunique()\n",
        "\n",
        "unique_names = full_df['text_name'].nunique()\n",
        "\n",
        "print(\"number of unique ids: \", unique_ids)\n",
        "print(\"number of unique names: \", unique_names)"
      ],
      "metadata": {
        "id": "BYMo74j1X6Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge quotes, speakers, verbs separated by newline\n",
        "merged_df = full_df.groupby(['text_id', 'text_name']).agg({\n",
        "    'quote': lambda x: '\\n'.join(x),\n",
        "    'speaker': lambda x: '\\n'.join(map(str, x)),\n",
        "    'verb': lambda x: '\\n'.join(map(str, x))\n",
        "}).reset_index()\n",
        "\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "ALr0ilvrROaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up speaker and verb columns by replacing 'nan' with newlines\n",
        "for index, row in merged_df.iterrows():\n",
        "  speakers = re.sub(r'nan', '\\n', merged_df.loc[index, 'speaker'])\n",
        "  verbs = re.sub(r'nan', '\\n', merged_df.loc[index, 'verb'])\n",
        "\n",
        "  merged_df.loc[index, 'speaker'] = speakers\n",
        "  merged_df.loc[index, 'verb'] = verbs"
      ],
      "metadata": {
        "id": "s8YyX75sSr4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge the updated full dataframe with the non_quotes dataframe\n",
        "# with the new headers text_id, text_name, quote, speaker, verb, non_quoted_text\n",
        "# merges on shared text id - articles that do not contain quotes are omitted\n",
        "output_df = pd.merge(merged_df, non_quotes_df, on=['text_id', 'text_name'])\n",
        "\n",
        "output_df.head()"
      ],
      "metadata": {
        "id": "qlB8c4o8UvCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remember to replace the output file path with your own specifications"
      ],
      "metadata": {
        "id": "f6o0aYhZesyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write dataframe to excel sheet\n",
        "# replace this file path with the correct/relevant file path\n",
        "output = '/content/drive/My Drive/evaluation_quotes/CBC_qt_output/2023_06_jun_CBC_news_clean.xlsx'\n",
        "\n",
        "output_df.to_excel(output, index=False)"
      ],
      "metadata": {
        "id": "6KFB6rbTZH7l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}