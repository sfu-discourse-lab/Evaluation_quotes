{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analyzer for News Quotes\n",
        "\n",
        "1. Read cleaned data into a pandas dataframe\n",
        "2. Pass quotes from each article into sentiment analyzer\n",
        "3. Save output into new columns 'negative', 'neutral', 'positive', 'compound'\n",
        "4. Save output into new excel sheet with two sheets, one for quotes and one for non-quotes"
      ],
      "metadata": {
        "id": "RG1_hbnQbPlQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhjOINLHbELR"
      },
      "outputs": [],
      "source": [
        "# run this code if connecting to a Google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "JfZEJ-7meKr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "RIRCT71CeIOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Data from Excel Files"
      ],
      "metadata": {
        "id": "gW1EacgmeTc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace with quotes_input.xlsx\n",
        "fp = '/content/drive/My Drive/evaluation_quotes/CBC_qt_output/2023_01_jan_CBC_news_clean.xlsx'\n",
        "\n",
        "quotes_df = pd.read_excel(fp, usecols = [\"text_id\", \"text_name\", \"quote\"])\n",
        "\n",
        "non_quotes_df = pd.read_excel(fp, usecols = [\"text_id\", \"text_name\", \"non_quoted_text\"])\n",
        "\n",
        "speakers_df = pd.read_excel(fp, usecols = [\"text_id\", \"text_name\", \"speaker\"])\n",
        "\n",
        "verbs_df = pd.read_excel(fp, usecols = [\"text_id\", \"text_name\", \"verb\"])"
      ],
      "metadata": {
        "id": "UdKIjPwKeSwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add new columns to dataframes\n",
        "quotes_df['positive'] = pd.Series(dtype='float')\n",
        "quotes_df['negative'] = pd.Series(dtype='float')\n",
        "quotes_df['neutral'] = pd.Series(dtype='float')\n",
        "quotes_df['compound'] = pd.Series(dtype='float')\n",
        "\n",
        "non_quotes_df['positive'] = pd.Series(dtype='float')\n",
        "non_quotes_df['negative'] = pd.Series(dtype='float')\n",
        "non_quotes_df['neutral'] = pd.Series(dtype='float')\n",
        "non_quotes_df['compound'] = pd.Series(dtype='float')\n",
        "\n",
        "speakers_df['positive'] = pd.Series(dtype='float')\n",
        "speakers_df['negative'] = pd.Series(dtype='float')\n",
        "speakers_df['neutral'] = pd.Series(dtype='float')\n",
        "speakers_df['compound'] = pd.Series(dtype='float')\n",
        "\n",
        "verbs_df['positive'] = pd.Series(dtype='float')\n",
        "verbs_df['negative'] = pd.Series(dtype='float')\n",
        "verbs_df['neutral'] = pd.Series(dtype='float')\n",
        "verbs_df['compound'] = pd.Series(dtype='float')"
      ],
      "metadata": {
        "id": "dagWdg12lOI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Quotes through VADER\n",
        "\n",
        "Vader Documentation: https://github.com/cjhutto/vaderSentiment\n",
        "\n",
        "Guide to using Vader: https://medium.com/@rslavanyageetha/vader-a-comprehensive-guide-to-sentiment-analysis-in-python-c4f1868b0d2e\n",
        "\n",
        "Vader sentiment analyzer returns a dictionary of sentiment intensity scores for\n",
        "a particular text input with the following sentiments: negative, neutral,\n",
        "positive, and compound for overall sentiment intensity. The negative, neutral,\n",
        "and positive scores have a value from 0 to 1 and compound scores have a\n",
        "value from -1 to 1, with -1 indicating entirely negative, 0 indicating\n",
        "entirely neutral, and 1 indicating entirely positive.\n"
      ],
      "metadata": {
        "id": "rn8yx9rFhS2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to extract scores for each story\n",
        "# args: dataframe, column name of text to be analyzed as a string\n",
        "def get_sentiment_score(df, col):\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    score = analyzer.polarity_scores(df[col][index])\n",
        "\n",
        "    df.loc[index, 'positive'] = score['pos']\n",
        "    df.loc[index, 'negative'] = score['neg']\n",
        "    df.loc[index, 'neutral'] = score['neu']\n",
        "    df.loc[index, 'compound'] = score['compound']"
      ],
      "metadata": {
        "id": "sncldllAinK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get sentiment scores for all four dataframes\n",
        "get_sentiment_score(quotes_df, 'quote')\n",
        "\n",
        "get_sentiment_score(non_quotes_df, 'non_quoted_text')\n",
        "\n",
        "get_sentiment_score(speakers_df, 'speaker')\n",
        "\n",
        "get_sentiment_score(verbs_df, 'verb')"
      ],
      "metadata": {
        "id": "0BHvVGmngPKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quotes_df.head()"
      ],
      "metadata": {
        "id": "Sb1t0s5grHyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_quotes_df.head()"
      ],
      "metadata": {
        "id": "KBRIMdV3tbd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speakers_df.head()"
      ],
      "metadata": {
        "id": "GWbhOkevswxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verbs_df.head()"
      ],
      "metadata": {
        "id": "9mIm7m_F0ZGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a third dataframe to directly compare compound scores between quotes and non quotes\n",
        "scores_all_df = pd.merge(quotes_df[['text_id', 'text_name', 'positive', 'negative', 'compound']],\n",
        "                          non_quotes_df[['text_id', 'text_name', 'positive', 'negative', 'compound']],\n",
        "                          on=['text_id', 'text_name'],\n",
        "                          suffixes=('_quotes', '_non_quotes'))\n",
        "\n",
        "scores_all_df.rename(columns={'positive_quotes': 'quote_pos',\n",
        "                              'negative_quotes': 'quote_neg',\n",
        "                              'compound_quotes': 'quote_comp',\n",
        "                              'positive_non_quotes': 'non_quote_pos',\n",
        "                              'negative_non_quotes': 'non_quote_neg',\n",
        "                              'compound_non_quotes': 'non_quote_comp',\n",
        "                              }, inplace=True)"
      ],
      "metadata": {
        "id": "gYSn8o4Ri4HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_all_df.head()"
      ],
      "metadata": {
        "id": "7AomSOXD2YMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary Calculations\n",
        "Add the following columns to the dataframe:\n",
        "* quote_prop_difference: positive score - negative score\n",
        "* quote_prop_direction: if it leans positive (>0), negative (<0), or neutral (=0)\n",
        "* same for non-quotes: non_quote_prop_difference and non_quote_prop_direction"
      ],
      "metadata": {
        "id": "XJYsNPJFqPqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate score differences for quotes and non_quotes\n",
        "scores_all_df.insert(5, 'quote_prop_difference', scores_all_df['quote_pos'] - scores_all_df['quote_neg'])\n",
        "\n",
        "scores_all_df.insert(9, 'non_quote_prop_difference', scores_all_df['non_quote_pos'] - scores_all_df['non_quote_neg'])"
      ],
      "metadata": {
        "id": "FHqWpRTmqGKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_all_df.head()"
      ],
      "metadata": {
        "id": "zqjqVCwB25-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# determine sentiment direction\n",
        "direction = ['positive', 'negative', 'neutral']\n",
        "\n",
        "quote_conds = [\n",
        "    scores_all_df.quote_prop_difference > 0,\n",
        "    scores_all_df.quote_prop_difference < 0,\n",
        "    scores_all_df.quote_prop_difference == 0,\n",
        "]\n",
        "\n",
        "quote_prop_direction = []\n",
        "\n",
        "quote_prop_direction = np.select(quote_conds, direction)\n",
        "\n",
        "scores_all_df.insert(6, 'quote_prop_direction', quote_prop_direction)\n",
        "\n",
        "non_quote_conds = [\n",
        "    scores_all_df.non_quote_prop_difference > 0,\n",
        "    scores_all_df.non_quote_prop_difference < 0,\n",
        "    scores_all_df.non_quote_prop_difference == 0,\n",
        "]\n",
        "\n",
        "scores_all_df['non_quote_prop_direction'] = np.select(non_quote_conds, direction)"
      ],
      "metadata": {
        "id": "ATLP564b27c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_all_df.head()"
      ],
      "metadata": {
        "id": "-NzGWBRF3NRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate Data\n",
        "Add a new sheet (dataframe) called 'summary' with the following columns:\n",
        "* Col 1 values: quote, non_quote, verbs, speakers\n",
        "* Headers:\n",
        "  * compound_max: max value of compound scores\n",
        "  * compound_min: min value of compound scores\n",
        "  * compound_avg: average value of compound scores\n",
        "  * pos_comp_count: number of compound scores that lean positive (exclude everything in the range [-0.05, 0.05])\n",
        "  * neg_comp_count: number of compound scores that lean negative\n",
        "  * avg_prop_diff: average value of proportion difference\n",
        "  * pos_prop_dir_count: number of texts that lean positive from difference\n",
        "  * neg_prop_dir_count: number of texts that lean negative from difference\n",
        "  * avg_pos_prop_diff: average value of proportion difference between positive differences\n",
        "  * avg_neg_prop_diff: average value of proportion difference between negative differences"
      ],
      "metadata": {
        "id": "_Ghd_HtBy3Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for extracting all the necessary data for each category\n",
        "# where df1 is the original dataframe of each category\n",
        "# and df2 is the scores all dataframe\n",
        "def aggregate_data(df1, df2, category):\n",
        "  row = []\n",
        "\n",
        "  # max/min/avg of compound scores\n",
        "  row.append(df1['compound'].max())\n",
        "  row.append(df1['compound'].min())\n",
        "  row.append(df1['compound'].mean())\n",
        "\n",
        "  # pos and neg comp count\n",
        "  row.append(df1.compound[df1.compound > 0.05].count())\n",
        "  row.append(df1.compound[df1.compound < -0.05].count())\n",
        "\n",
        "  # if category is quotes or non quotes, find the following values\n",
        "  # otherwise append 0s\n",
        "  if category != '':\n",
        "    prop_diff = category + '_prop_difference'\n",
        "    row.append(df2[prop_diff].mean())\n",
        "\n",
        "    # pos and neg direction counts\n",
        "    prop_dir = category + '_prop_direction'\n",
        "    row.append(df2[prop_dir][df2[prop_dir] == 'positive'].count())\n",
        "    row.append(df2[prop_dir][df2[prop_dir] == 'negative'].count())\n",
        "\n",
        "    # pos and neg difference means\n",
        "    row.append(df2[prop_diff][df2[prop_diff] > 0].mean())\n",
        "    row.append(df2[prop_diff][df2[prop_diff] < 0].mean())\n",
        "\n",
        "  else:\n",
        "    row = row + [0, 0, 0, 0, 0]\n",
        "\n",
        "  return row"
      ],
      "metadata": {
        "id": "r-52KL3P5iwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create summary dataframe\n",
        "data_summary = []\n",
        "\n",
        "data_summary.append(aggregate_data(quotes_df, scores_all_df, 'quote'))\n",
        "data_summary.append(aggregate_data(non_quotes_df, scores_all_df, 'non_quote'))\n",
        "data_summary.append(aggregate_data(speakers_df, scores_all_df, ''))\n",
        "data_summary.append(aggregate_data(verbs_df, scores_all_df, ''))\n",
        "\n",
        "summary_df = pd.DataFrame(data_summary)\n",
        "\n",
        "# row and column headers\n",
        "row_labels = ['quote', 'non_quote', 'speaker', 'verb']\n",
        "col_labels = ['compound_max', 'compound_min', 'compound_avg',\n",
        "              'pos_comp_count', 'neg_comp_count', 'avg_prop_diff',\n",
        "              'pos_prop_direction_count', 'neg_prop_direction_count',\n",
        "              'avg_pos_prop_difference', 'avg_neg_prop_difference']\n",
        "\n",
        "summary_df.index = row_labels\n",
        "summary_df.columns = col_labels"
      ],
      "metadata": {
        "id": "25xmjg1O43ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_df.head()"
      ],
      "metadata": {
        "id": "jiPbONG1CBL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Output to New Workbook"
      ],
      "metadata": {
        "id": "ICLfCIHhtvOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "id": "cKjUTq3Uwg9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace with 'quotes_sentiment.xlsx'\n",
        "output = '/content/drive/My Drive/evaluation_quotes/CBC_sentiment_output/2023_01_jan_CBC_news_sentiment.xlsx'\n",
        "\n",
        "# create excel writer object to initialize new workbook\n",
        "writer = pd.ExcelWriter(output, engine=\"xlsxwriter\")\n",
        "\n",
        "# write dataframes to different worksheets\n",
        "quotes_df.to_excel(writer, sheet_name=\"quotes\", index=False)\n",
        "non_quotes_df.to_excel(writer, sheet_name=\"non_quotes\", index=False)\n",
        "scores_all_df.to_excel(writer, sheet_name=\"scores_all\", index=False)\n",
        "summary_df.to_excel(writer, sheet_name=\"summary\")\n",
        "\n",
        "# close the excel writer and output file\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "knDTwEawj5yb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}